
# For training with 
# - multipack dataloader
# - per token loss averaging across GPUs
# - padding-free attention via injection into HF models
training:

  dataloader:
    multipack:

      effective_batch_size: 3840

      max_number_tokens: 60000

  loss:
    # if we need to change the loss computation
    # maybe we can do it in 
    across_gpus:
      reduction: mean
      resolution: token

  attention:
    padding_free: 
      method: "huggingface-injected"

