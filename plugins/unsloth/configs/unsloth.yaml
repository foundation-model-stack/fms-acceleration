# PEFT-related acceleration
peft:

  # quantization-releated acceleration
  # e.g., kernels for quantized base weights
  quantization: 

    unsloth: 

      # load unsloth optimizations for these 4bit base layer weights.
      # currently only support "auto_gptq" and "bitsandbytes"
      base_layer: 

      # activate various unsloth optimizations
      # NOTE: currently supports only all-or-nothing.

      # fused kernels for lora linear layers
      fused_lora: True

      # fast loss triton kernels
      fast_loss: True

      # fast rms norm triton kernels
      fast_rsm_layernorm: True

      # fast RoPE embedding triton kernels
      fast_rope_embeddings: True